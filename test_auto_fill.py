"""
Script pour pr√©-remplir automatiquement le questionnaire.
Utilisez ce profil pour tester l'application rapidement.
"""

# Profil de test : Data Scientist Avanc√©
TEST_PROFILE = {
    1: "4 - Avanc√©",
    2: "J'ai 3 ans d'exp√©rience en analyse de donn√©es avec pandas, numpy pour la manipulation de donn√©es, et scipy pour les calculs scientifiques. J'ai travaill√© sur des projets d'analyse de ventes, de segmentation client avec K-means, et de pr√©diction de churn avec des mod√®les de classification. J'utilise quotidiennement Jupyter Notebook pour l'analyse exploratoire et la cr√©ation de rapports interactifs.",
    3: ["Matplotlib", "Seaborn", "Plotly", "Power BI"],
    4: "4 - Avanc√©",
    5: {
        'main': "Oui, occasionnellement",
        'followup': "J'ai utilis√© NLTK et spaCy pour la tokenization dans des projets d'analyse de sentiments sur des avis clients et de classification de textes. J'ai aussi exp√©riment√© avec des tokenizers de transformers comme BERT pour des t√¢ches de NLP avanc√©es."
    },
    6: "MySQL/PostgreSQL",
    7: ["R√©gression lin√©aire/logistique", "Random Forest", "XGBoost/LightGBM", "Neural Networks"],
    8: "3 - Interm√©diaire",
    9: "J'ai d√©velopp√© un mod√®le de pr√©diction de churn pour une entreprise de t√©l√©communications avec XGBoost. Apr√®s avoir test√© plusieurs algorithmes (Random Forest, Logistic Regression, SVM), le mod√®le final atteint 87% de pr√©cision et 82% de recall. J'ai cr√©√© un dashboard Power BI pour suivre les pr√©dictions en temps r√©el et identifier les clients √† risque. Ce projet a permis de r√©duire le taux de churn de 15% en 6 mois.",
    10: ["AWS", "Google Cloud Platform"]
}

# Profil alternatif : D√©butant en Data
TEST_PROFILE_BEGINNER = {
    1: "2 - √âl√©mentaire",
    2: "Je commence √† apprendre l'analyse de donn√©es. J'ai suivi des tutoriels en ligne sur pandas et j'ai fait quelques exercices sur Kaggle. Je sais lire des fichiers CSV et faire des statistiques descriptives basiques.",
    3: ["Matplotlib"],
    4: "1 - D√©butant",
    5: {
        'main': "Je ne sais pas ce que c'est",
        'followup': ""
    },
    6: "Aucune",
    7: ["R√©gression lin√©aire/logistique"],
    8: "2 - √âl√©mentaire",
    9: "J'ai fait un petit projet d'analyse des ventes d'un magasin fictif avec pandas. J'ai calcul√© des moyennes et cr√©√© quelques graphiques simples avec matplotlib.",
    10: ["Aucun"]
}

# Profil Expert : Machine Learning Engineer
TEST_PROFILE_EXPERT = {
    1: "5 - Expert",
    2: "J'ai 5+ ans d'exp√©rience en data science et machine learning. Expert en pandas, numpy, scikit-learn, et frameworks de deep learning (TensorFlow, PyTorch). J'ai d√©ploy√© plus de 20 mod√®les en production sur AWS et GCP. Sp√©cialis√© dans les pipelines MLOps avec Airflow, MLflow et Kubeflow. J'ai √©galement contribu√© √† des projets open-source dans l'√©cosyst√®me Python data science.",
    3: ["Matplotlib", "Seaborn", "Plotly", "Tableau", "Power BI", "D3.js"],
    4: "5 - Expert",
    5: {
        'main': "Oui, r√©guli√®rement",
        'followup': "Expert en NLP avec transformers (BERT, GPT, T5). J'ai d√©velopp√© des syst√®mes de tokenization personnalis√©s pour des langues peu dot√©es. Ma√Ætrise de Hugging Face, spaCy avanc√©, et cr√©ation de mod√®les de langue from scratch."
    },
    6: "MySQL/PostgreSQL",
    7: ["R√©gression lin√©aire/logistique", "Arbres de d√©cision", "Random Forest", "XGBoost/LightGBM", "Neural Networks", "Deep Learning"],
    8: "5 - Expert",
    9: "J'ai architectur√© et d√©ploy√© un syst√®me de recommandation temps r√©el pour un e-commerce (10M+ utilisateurs) utilisant des embeddings neuronaux et du collaborative filtering. Le syst√®me traite 5000 req/s avec une latence <50ms sur Kubernetes. J'ai aussi d√©velopp√© un mod√®le de d√©tection de fraude avec deep learning atteignant 99.2% de pr√©cision, r√©duisant les pertes de 3M‚Ç¨/an. Publication de 2 papers en conf√©rence ML.",
    10: ["AWS", "Azure", "Google Cloud Platform"]
}

def print_profile(profile_name, profile):
    """Affiche un profil de test."""
    print(f"\n{'='*60}")
    print(f"PROFIL DE TEST : {profile_name}")
    print('='*60)
    
    questions = [
        "Niveau Python",
        "Exp√©rience analyse de donn√©es",
        "Outils de visualisation",
        "Niveau Machine Learning",
        "Tokenization NLP",
        "Base de donn√©es principale",
        "Comp√©tences ML",
        "Niveau statistiques",
        "Projet data science",
        "Services cloud"
    ]
    
    for i, (q_id, response) in enumerate(profile.items(), 1):
        print(f"\nQuestion {i}: {questions[i-1]}")
        if isinstance(response, dict):
            print(f"  ‚Üí {response['main']}")
            if response['followup']:
                print(f"    D√©tail: {response['followup'][:80]}...")
        elif isinstance(response, list):
            print(f"  ‚Üí {', '.join(response)}")
        elif isinstance(response, str) and len(response) > 100:
            print(f"  ‚Üí {response[:100]}...")
        else:
            print(f"  ‚Üí {response}")


if __name__ == "__main__":
    print("\n" + "üéì PROFILS DE TEST AISCA ".center(60, "="))
    
    print_profile("DATA SCIENTIST AVANC√â (RECOMMAND√â)", TEST_PROFILE)
    print_profile("D√âBUTANT EN DATA", TEST_PROFILE_BEGINNER)
    print_profile("MACHINE LEARNING ENGINEER EXPERT", TEST_PROFILE_EXPERT)
    
    print("\n" + "="*60)
    print("\nüí° Pour utiliser ces profils :")
    print("   1. Copiez-collez les r√©ponses manuellement dans Streamlit")
    print("   2. Ou utilisez le profil dans un test automatis√©")
    print("\n" + "="*60 + "\n")
